{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ef85cc",
   "metadata": {},
   "source": [
    "# Variational encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eba7db",
   "metadata": {},
   "source": [
    "## import lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31dc0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam\n",
    "import cudnn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity, LocalOutlierFactor\n",
    "\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb35e968",
   "metadata": {},
   "source": [
    "## ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af497ac5",
   "metadata": {},
   "source": [
    "### Step 0. Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "00d48352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "batch_size = 100\n",
    "x_dim = 19\n",
    "hidden_dim = 1024\n",
    "latent_dim = 19\n",
    "\n",
    "lr = 0.5e-3\n",
    "epochs = 30\n",
    "\n",
    "training_seed = 21\n",
    "\n",
    "state_dim = 64\n",
    "action_dim = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692ad4d",
   "metadata": {},
   "source": [
    "### Step 1. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d02f9be",
   "metadata": {},
   "source": [
    "get data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "0a312489",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 30\n",
    "all_state_dim = 64\n",
    "seed = 0\n",
    "# Load fullstate\n",
    "data_fullstate = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_pos = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_vel = np.empty(num_seeds, dtype=object)\n",
    "data_no_action = np.empty(num_seeds, dtype=object)\n",
    "data_no_imu = np.empty(num_seeds, dtype=object)\n",
    "data_no_fc = np.empty(num_seeds, dtype=object)\n",
    "for i in range(num_seeds):\n",
    "    data_fullstate[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-fullstate-rand-{i}.npz\")    \n",
    "    data_no_joint_pos[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_pos-rand-{i}.npz\")\n",
    "    data_no_joint_vel[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_vel-rand-{i}.npz\")\n",
    "    data_no_action[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_action-rand-{i}.npz\")\n",
    "    data_no_imu[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_imu-rand-{i}.npz\")\n",
    "    data_no_fc[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_fc-rand-{i}.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "085b1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.empty((0, all_state_dim), dtype=torch.float32 ,device=DEVICE)\n",
    "train_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_x = torch.empty((0, all_state_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "for i in range(training_seed):\n",
    "    train_x = torch.cat((train_x, torch.tensor(data_fullstate[i][\"state\"].reshape(data_fullstate[i][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    train_y = torch.cat((train_y, torch.tensor(data_fullstate[i][\"action_lowpass\"].reshape(data_fullstate[i][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "for j in range(training_seed, num_seeds):\n",
    "    test_x = torch.cat((test_x, torch.tensor(data_no_joint_pos[j][\"state\"].reshape(data_no_joint_pos[j][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    test_y = torch.cat((test_y, torch.tensor(data_no_joint_pos[j][\"action_lowpass\"].reshape(data_no_joint_pos[j][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cd154",
   "metadata": {},
   "source": [
    "Converge to TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "632c462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : X , Y shape :  torch.Size([21000, 19]) torch.Size([21000, 19])\n",
      "TEST : X , Y shape :  torch.Size([9000, 19]) torch.Size([9000, 19])\n"
     ]
    }
   ],
   "source": [
    "state_index = torch.arange(0, 19)\n",
    "state_dim = len(state_index)\n",
    "\n",
    "train_dataset = TensorDataset(train_x[:,state_index], train_y)\n",
    "test_dataset = TensorDataset(test_x[:,state_index], test_y)\n",
    "\n",
    "print(\"TRAIN : X , Y shape : \",train_x[:,state_index].shape , train_y.shape)\n",
    "print(\"TEST : X , Y shape : \",test_x[:,state_index].shape , test_y.shape)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d0238",
   "metadata": {},
   "source": [
    "### Step 2. Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "42fe723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    A simple implementation of Gaussian MLP Encoder\n",
    "\"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)         # encoder produces mean and log of variance \n",
    "        log_var  = self.FC_var(h_)          # (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        z = self.reparameterization(mean, torch.exp(log_var))  # takes exponential function (log var -> var) # reparameterization trick\n",
    "        # z is sampling from the distribution z = mean + var * epsilon\n",
    "        return z,mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "b1e4464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(input_dim=state_dim, hidden_dim=hidden_dim, latent_dim=latent_dim).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44d36f",
   "metadata": {},
   "source": [
    "### Step 3. Define Loss function\n",
    "- using MSE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50a69e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}(z,\\hat{z}) = \\| z^2 - \\hat{z}^2 \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "0d01f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEloss = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    # reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    reproduction_loss = MSEloss(x_hat, x)  # Using MSE loss instead of binary cross entropy\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d0b43",
   "metadata": {},
   "source": [
    "### Step 4. Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "f4fe0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 complete! \tAverage Loss:  0.0002454508574229429\n",
      "\tEpoch 2 complete! \tAverage Loss:  1.8951946173367898e-06\n",
      "\tEpoch 3 complete! \tAverage Loss:  6.15748618247598e-07\n",
      "\tEpoch 4 complete! \tAverage Loss:  6.477965149080434e-07\n",
      "\tEpoch 5 complete! \tAverage Loss:  9.537090975724375e-07\n",
      "\tEpoch 6 complete! \tAverage Loss:  9.703886450190903e-07\n",
      "\tEpoch 7 complete! \tAverage Loss:  9.046888738047915e-07\n",
      "\tEpoch 8 complete! \tAverage Loss:  9.355765779440861e-07\n",
      "\tEpoch 9 complete! \tAverage Loss:  9.860106398594904e-07\n",
      "\tEpoch 10 complete! \tAverage Loss:  8.287672871115515e-07\n",
      "\tEpoch 11 complete! \tAverage Loss:  1.2189468038719566e-06\n",
      "\tEpoch 12 complete! \tAverage Loss:  7.598737265565711e-07\n",
      "\tEpoch 13 complete! \tAverage Loss:  7.389264263972444e-07\n",
      "\tEpoch 14 complete! \tAverage Loss:  9.56544566801504e-07\n",
      "\tEpoch 15 complete! \tAverage Loss:  5.708548105845416e-07\n",
      "\tEpoch 16 complete! \tAverage Loss:  9.119501496505318e-07\n",
      "\tEpoch 17 complete! \tAverage Loss:  6.567881810129342e-07\n",
      "\tEpoch 18 complete! \tAverage Loss:  8.165223065867595e-07\n",
      "\tEpoch 19 complete! \tAverage Loss:  5.765774928507647e-07\n",
      "\tEpoch 20 complete! \tAverage Loss:  6.317838350866262e-07\n",
      "\tEpoch 21 complete! \tAverage Loss:  7.021864392595816e-07\n",
      "\tEpoch 22 complete! \tAverage Loss:  6.431587105594647e-07\n",
      "\tEpoch 23 complete! \tAverage Loss:  5.520081363950352e-07\n",
      "\tEpoch 24 complete! \tAverage Loss:  5.993741912166833e-07\n",
      "\tEpoch 25 complete! \tAverage Loss:  5.293502271817062e-07\n",
      "\tEpoch 26 complete! \tAverage Loss:  4.692852813065382e-07\n",
      "\tEpoch 27 complete! \tAverage Loss:  6.075557030271739e-07\n",
      "\tEpoch 28 complete! \tAverage Loss:  5.548654919831108e-07\n",
      "\tEpoch 29 complete! \tAverage Loss:  4.070020204990084e-07\n",
      "\tEpoch 30 complete! \tAverage Loss:  3.55588268253935e-07\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        # loss = loss_function(x, x_hat, mean, log_var)\n",
    "        loss = MSEloss(x_hat,x)\n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
    "    \n",
    "print(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "1c9af63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 783.85it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "        \n",
    "        x_hat, _, _ = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "d1bf0c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9000, 19])"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[:,state_index].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "529bca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0020,  0.0414, -0.0142, -0.0121, -0.0397, -0.0026,  0.0255,  0.0123,\n",
      "         0.0194, -0.0125,  0.0339, -0.0033, -0.0336,  0.0052,  0.0018, -0.0195,\n",
      "         0.0227,  0.0323,  0.0128], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7372,  1.4372,  0.1268,  0.0081, -0.7416, -0.4339, -1.0284,  0.6189,\n",
      "        -0.3128,  0.9724,  0.3812, -0.7159,  0.7134,  0.0651, -0.6631, -0.4465,\n",
      "         1.3070,  0.4355,  1.1686], device='cuda:0', grad_fn=<NormalBackward3>)\n",
      "tensor([ 0.3439,  0.2428,  0.3439, -0.3416, -0.2206,  0.3439,  0.3117, -0.1444,\n",
      "        -0.3436, -0.3439, -0.1670,  0.1925, -0.1582, -0.3439, -0.3439, -0.1447,\n",
      "         0.1695,  0.3404, -0.0277], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "print(model(test_x[idx , state_index])[0])\n",
    "print(torch.normal( model(test_x[idx , state_index])[1], torch.exp(model(test_x[idx , state_index])[1])))\n",
    "print(test_y[idx , state_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "82c744a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0149, 0.0153, 0.0141, 0.0140, 0.0137, 0.0145, 0.0151, 0.0142, 0.0142,\n",
      "        0.0148, 0.0144, 0.0146, 0.0143, 0.0143, 0.0145, 0.0141, 0.0150, 0.0143,\n",
      "        0.0137], device='cuda:0', grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print( torch.exp(model(test_x[idx , state_index])[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "9bc9fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0162, -0.0014, -0.0135, -0.0236, -0.0172, -0.0156, -0.0043,  0.0094,\n",
      "         0.0125, -0.0195,  0.0368, -0.0032, -0.0286,  0.0074, -0.0033,  0.0004,\n",
      "         0.0006,  0.0142,  0.0132], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((model(test_x[idx , state_index])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fc223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
