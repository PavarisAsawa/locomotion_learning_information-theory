{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceca9e3f",
   "metadata": {},
   "source": [
    "# Optuna Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330d9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init\n",
    "import cudnn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity, LocalOutlierFactor\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5627f2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29dbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "num_seeds = 30\n",
    "seed = 0\n",
    "\n",
    "all_state_dim = 64\n",
    "state_dim = 64\n",
    "action_dim = 19\n",
    "training_seed = 21\n",
    "\n",
    "# Load fullstate\n",
    "data_fullstate = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_pos = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_vel = np.empty(num_seeds, dtype=object)\n",
    "data_no_action = np.empty(num_seeds, dtype=object)\n",
    "data_no_imu = np.empty(num_seeds, dtype=object)\n",
    "data_no_fc = np.empty(num_seeds, dtype=object)\n",
    "for i in range(num_seeds):\n",
    "    data_fullstate[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-fullstate-rand-{i}.npz\")    \n",
    "    data_no_joint_pos[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_pos-rand-{i}.npz\")\n",
    "    data_no_joint_vel[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_vel-rand-{i}.npz\")\n",
    "    data_no_action[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_action-rand-{i}.npz\")\n",
    "    data_no_imu[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_imu-rand-{i}.npz\")\n",
    "    data_no_fc[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_fc-rand-{i}.npz\")\n",
    "    \n",
    "train_x = torch.empty((0, all_state_dim), dtype=torch.float32 ,device=DEVICE)\n",
    "train_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_x = torch.empty((0, all_state_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "for i in range(training_seed):\n",
    "    train_x = torch.cat((train_x, torch.tensor(data_fullstate[i][\"state\"].reshape(data_fullstate[i][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    train_y = torch.cat((train_y, torch.tensor(data_fullstate[i][\"action_lowpass\"].reshape(data_fullstate[i][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "for j in range(training_seed, num_seeds):\n",
    "    test_x = torch.cat((test_x, torch.tensor(data_no_joint_pos[j][\"state\"].reshape(data_no_joint_pos[j][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    test_y = torch.cat((test_y, torch.tensor(data_no_joint_pos[j][\"action_lowpass\"].reshape(data_no_joint_pos[j][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6a0f8",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0e828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    A simple implementation of Gaussian MLP Encoder\n",
    "\"\"\"\n",
    "class Predictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.FC_mean  = nn.Linear(hidden_dim, output_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        # self.LeakyReLU = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def reparameterization(self , mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_       = self.tanh(self.FC_input(x))\n",
    "        h_       = self.tanh(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)         # encoder produces mean and log of variance \n",
    "        log_var  = self.FC_var(h_)          # (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        # log_var  = self.softplus(log_var)  # clamp log_var to avoid numerical issues\n",
    "        \n",
    "        z = self.reparameterization(mean, torch.exp(log_var))  # reparameterization trick\n",
    "        # z is sampling from the distribution z = mean + var * epsilon\n",
    "        return z,mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c824d",
   "metadata": {},
   "source": [
    "## Optuna setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170932f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : X , Y shape :  torch.Size([21000, 19]) torch.Size([21000, 19])\n",
      "TEST : X , Y shape :  torch.Size([9000, 19]) torch.Size([9000, 19])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "state_index = torch.arange(0, 19) \n",
    "state_dim = len(state_index)\n",
    "\n",
    "train_dataset = TensorDataset(train_x[:,state_index], train_y)\n",
    "test_dataset = TensorDataset(test_x[:,state_index], test_y)\n",
    "\n",
    "print(\"TRAIN : X , Y shape : \",train_x[:,state_index].shape , train_y.shape)\n",
    "print(\"TEST : X , Y shape : \",test_x[:,state_index].shape , test_y.shape)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aced5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "input_dim = state_dim\n",
    "output_dim = 19\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb91f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128,256 ,512, 1024])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512, 1024, 2048])    \n",
    "\n",
    "    model = Predictor(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(DEVICE)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(DEVICE)    # dim = [batch_size, state_dim]\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred, mean , log_var = model(x_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x_batch.size(0)\n",
    "            \n",
    "\n",
    "        avg_loss = total_loss / len(train_dataset)\n",
    "        trial.report(avg_loss, epoch)\n",
    "        # train_losses.append(avg_loss)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2cd48f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 05:05:28,563] A new study created in memory with name: no-name-c0266b4b-65cd-4fa6-9d4b-8f28cdd440b2\n",
      "[I 2025-08-13 05:06:20,771] Trial 0 finished with value: 0.013385790361180191 and parameters: {'lr': 0.004795453780801065, 'hidden_dim': 64, 'batch_size': 256}. Best is trial 0 with value: 0.013385790361180191.\n",
      "[I 2025-08-13 05:07:41,504] Trial 1 finished with value: 0.0118262100035236 and parameters: {'lr': 0.0019740394110345657, 'hidden_dim': 128, 'batch_size': 128}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:09:00,141] Trial 2 finished with value: 0.016547026270202228 and parameters: {'lr': 0.015320397166460487, 'hidden_dim': 64, 'batch_size': 128}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:10:20,673] Trial 3 finished with value: 0.013563336574960323 and parameters: {'lr': 0.0006321526682710231, 'hidden_dim': 128, 'batch_size': 128}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:11:11,522] Trial 4 finished with value: 0.02249756548163437 and parameters: {'lr': 2.325859432112798e-05, 'hidden_dim': 64, 'batch_size': 256}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:12:28,520] Trial 5 finished with value: 29315.43307793899 and parameters: {'lr': 0.011318450525409862, 'hidden_dim': 512, 'batch_size': 128}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:13:00,297] Trial 6 finished with value: 0.01500297810846851 and parameters: {'lr': 0.02113717603034589, 'hidden_dim': 64, 'batch_size': 2048}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:14:13,912] Trial 7 finished with value: 0.012435138670106729 and parameters: {'lr': 0.0005367831429287339, 'hidden_dim': 256, 'batch_size': 128}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:15:02,263] Trial 8 finished with value: 260310.42349404763 and parameters: {'lr': 0.023789115300826787, 'hidden_dim': 256, 'batch_size': 256}. Best is trial 1 with value: 0.0118262100035236.\n",
      "[I 2025-08-13 05:15:33,641] Trial 9 finished with value: 0.011437920340469905 and parameters: {'lr': 0.009720841006333782, 'hidden_dim': 512, 'batch_size': 1024}. Best is trial 9 with value: 0.011437920340469905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  10\n",
      "Best trial:\n",
      "  Value:  0.011437920340469905\n",
      "  Params: \n",
      "    lr: 0.009720841006333782\n",
      "    hidden_dim: 512\n",
      "    batch_size: 1024\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
