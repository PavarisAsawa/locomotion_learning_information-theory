{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb73cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 30\n",
    "seed = 0\n",
    "# Load fullstate\n",
    "data_fullstate = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_pos = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_vel = np.empty(num_seeds, dtype=object)\n",
    "data_no_action = np.empty(num_seeds, dtype=object)\n",
    "data_no_imu = np.empty(num_seeds, dtype=object)\n",
    "data_no_fc = np.empty(num_seeds, dtype=object)\n",
    "for i in range(num_seeds):\n",
    "    data_fullstate[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-fullstate-rand-{i}.npz\")    \n",
    "    data_no_joint_pos[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_pos-rand-{i}.npz\")\n",
    "    data_no_joint_vel[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_joint_vel-rand-{i}.npz\")\n",
    "    data_no_action[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_action-rand-{i}.npz\")\n",
    "    data_no_imu[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_imu-rand-{i}.npz\")\n",
    "    data_no_fc[i] = np.load(f\"data/HEBB-FULL-STATE_seed-{seed}-no_fc-rand-{i}.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc789fe",
   "metadata": {},
   "source": [
    "## **Neural network model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "54f634aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, state_dim=64, action_dim=19, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu_head = nn.Linear(hidden_dim, action_dim)\n",
    "        self.var_head = nn.Sequential(\n",
    "        nn.Linear(hidden_dim, action_dim),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, state):\n",
    "        h = self.net(state)\n",
    "        \n",
    "        mu = self.mu_head(h)\n",
    "        var = self.var_head(h)\n",
    "        return mu, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7af44bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.tensor(data_fullstate[0][\"state\"].reshape(-1, 64))\n",
    "actions = torch.tensor(data_fullstate[0][\"action_lowpass\"].reshape(-1, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "49abef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(states, actions)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "discriminator = Discriminator(state_dim=64, action_dim=19)\n",
    "optimizer = optim.Adam(discriminator.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd35dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator, states, actions):\n",
    "    mu, var = discriminator(states)\n",
    "    var = torch.clamp(var, min=1e-6)  # ป้องกัน var เป็น 0\n",
    "    dist = torch.distributions.Normal(mu, var.sqrt())\n",
    "    log_prob = dist.log_prob(actions).sum(dim=-1)\n",
    "    return -log_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1392f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator, states, actions):\n",
    "    mu, var = discriminator(states)\n",
    "    var = torch.clamp(var, min=1e-6)\n",
    "    sigma = var.sqrt()\n",
    "    dist  = torch.distributions.Normal(mu, sigma)\n",
    "    log_prob = dist.log_prob(actions).sum(dim=-1)\n",
    "    return -log_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a79e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()          # creates an MSE loss module\n",
    "def discriminator_loss(discriminator, states, actions):\n",
    "    mu, var = discriminator(states)\n",
    "    loss  = criterion(mu, actions)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3e8d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Discriminator Loss = 0.3663\n",
      "Epoch 2: Discriminator Loss = 0.3493\n",
      "Epoch 3: Discriminator Loss = 0.3654\n",
      "Epoch 4: Discriminator Loss = 0.3271\n",
      "Epoch 5: Discriminator Loss = 0.3590\n",
      "Epoch 6: Discriminator Loss = 0.3480\n",
      "Epoch 7: Discriminator Loss = 0.3165\n",
      "Epoch 8: Discriminator Loss = 0.3413\n",
      "Epoch 9: Discriminator Loss = 0.3019\n",
      "Epoch 10: Discriminator Loss = 0.3149\n",
      "Epoch 11: Discriminator Loss = 0.2948\n",
      "Epoch 12: Discriminator Loss = 0.2847\n",
      "Epoch 13: Discriminator Loss = 0.2878\n",
      "Epoch 14: Discriminator Loss = 0.2695\n",
      "Epoch 15: Discriminator Loss = 0.2399\n",
      "Epoch 16: Discriminator Loss = 0.2167\n",
      "Epoch 17: Discriminator Loss = 0.2318\n",
      "Epoch 18: Discriminator Loss = 0.2408\n",
      "Epoch 19: Discriminator Loss = 0.1940\n",
      "Epoch 20: Discriminator Loss = 0.2000\n",
      "Epoch 21: Discriminator Loss = 0.1748\n",
      "Epoch 22: Discriminator Loss = 0.1561\n",
      "Epoch 23: Discriminator Loss = 0.1624\n",
      "Epoch 24: Discriminator Loss = 0.1421\n",
      "Epoch 25: Discriminator Loss = 0.1208\n",
      "Epoch 26: Discriminator Loss = 0.1210\n",
      "Epoch 27: Discriminator Loss = 0.1132\n",
      "Epoch 28: Discriminator Loss = 0.0999\n",
      "Epoch 29: Discriminator Loss = 0.0991\n",
      "Epoch 30: Discriminator Loss = 0.0917\n",
      "Epoch 31: Discriminator Loss = 0.0827\n",
      "Epoch 32: Discriminator Loss = 0.0753\n",
      "Epoch 33: Discriminator Loss = 0.0647\n",
      "Epoch 34: Discriminator Loss = 0.0619\n",
      "Epoch 35: Discriminator Loss = 0.0603\n",
      "Epoch 36: Discriminator Loss = 0.0572\n",
      "Epoch 37: Discriminator Loss = 0.0496\n",
      "Epoch 38: Discriminator Loss = 0.0498\n",
      "Epoch 39: Discriminator Loss = 0.0399\n",
      "Epoch 40: Discriminator Loss = 0.0358\n",
      "Epoch 41: Discriminator Loss = 0.0416\n",
      "Epoch 42: Discriminator Loss = 0.0393\n",
      "Epoch 43: Discriminator Loss = 0.0342\n",
      "Epoch 44: Discriminator Loss = 0.0310\n",
      "Epoch 45: Discriminator Loss = 0.0299\n",
      "Epoch 46: Discriminator Loss = 0.0303\n",
      "Epoch 47: Discriminator Loss = 0.0239\n",
      "Epoch 48: Discriminator Loss = 0.0289\n",
      "Epoch 49: Discriminator Loss = 0.0267\n",
      "Epoch 50: Discriminator Loss = 0.0247\n",
      "Epoch 51: Discriminator Loss = 0.0311\n",
      "Epoch 52: Discriminator Loss = 0.0283\n",
      "Epoch 53: Discriminator Loss = 0.0207\n",
      "Epoch 54: Discriminator Loss = 0.0200\n",
      "Epoch 55: Discriminator Loss = 0.0225\n",
      "Epoch 56: Discriminator Loss = 0.0248\n",
      "Epoch 57: Discriminator Loss = 0.0234\n",
      "Epoch 58: Discriminator Loss = 0.0235\n",
      "Epoch 59: Discriminator Loss = 0.0166\n",
      "Epoch 60: Discriminator Loss = 0.0217\n",
      "Epoch 61: Discriminator Loss = 0.0177\n",
      "Epoch 62: Discriminator Loss = 0.0203\n",
      "Epoch 63: Discriminator Loss = 0.0172\n",
      "Epoch 64: Discriminator Loss = 0.0181\n",
      "Epoch 65: Discriminator Loss = 0.0168\n",
      "Epoch 66: Discriminator Loss = 0.0192\n",
      "Epoch 67: Discriminator Loss = 0.0179\n",
      "Epoch 68: Discriminator Loss = 0.0203\n",
      "Epoch 69: Discriminator Loss = 0.0182\n",
      "Epoch 70: Discriminator Loss = 0.0219\n",
      "Epoch 71: Discriminator Loss = 0.0192\n",
      "Epoch 72: Discriminator Loss = 0.0186\n",
      "Epoch 73: Discriminator Loss = 0.0131\n",
      "Epoch 74: Discriminator Loss = 0.0184\n",
      "Epoch 75: Discriminator Loss = 0.0164\n",
      "Epoch 76: Discriminator Loss = 0.0162\n",
      "Epoch 77: Discriminator Loss = 0.0211\n",
      "Epoch 78: Discriminator Loss = 0.0196\n",
      "Epoch 79: Discriminator Loss = 0.0164\n",
      "Epoch 80: Discriminator Loss = 0.0165\n",
      "Epoch 81: Discriminator Loss = 0.0185\n",
      "Epoch 82: Discriminator Loss = 0.0172\n",
      "Epoch 83: Discriminator Loss = 0.0145\n",
      "Epoch 84: Discriminator Loss = 0.0152\n",
      "Epoch 85: Discriminator Loss = 0.0171\n",
      "Epoch 86: Discriminator Loss = 0.0196\n",
      "Epoch 87: Discriminator Loss = 0.0162\n",
      "Epoch 88: Discriminator Loss = 0.0167\n",
      "Epoch 89: Discriminator Loss = 0.0152\n",
      "Epoch 90: Discriminator Loss = 0.0205\n",
      "Epoch 91: Discriminator Loss = 0.0207\n",
      "Epoch 92: Discriminator Loss = 0.0132\n",
      "Epoch 93: Discriminator Loss = 0.0145\n",
      "Epoch 94: Discriminator Loss = 0.0164\n",
      "Epoch 95: Discriminator Loss = 0.0141\n",
      "Epoch 96: Discriminator Loss = 0.0175\n",
      "Epoch 97: Discriminator Loss = 0.0191\n",
      "Epoch 98: Discriminator Loss = 0.0166\n",
      "Epoch 99: Discriminator Loss = 0.0166\n",
      "Epoch 100: Discriminator Loss = 0.0147\n",
      "Saved model to discriminator.pth\n"
     ]
    }
   ],
   "source": [
    "# Train discriminator\n",
    "# for epoch in tqdm.tqdm(range(100)):\n",
    "for epoch in range(100):\n",
    "    for s, a in loader:\n",
    "        # s, a = s.cuda(), a.cuda()\n",
    "        loss = discriminator_loss(discriminator, s, a)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Discriminator Loss = {loss.item():.4f}\")\n",
    "# กำหนด path ที่จะบันทึก เช่น\n",
    "MODEL_PATH = \"discriminator.pth\"\n",
    "# เซฟ state_dict ของโมเดล\n",
    "torch.save(discriminator.state_dict(), MODEL_PATH)\n",
    "print(f\"Saved model to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c761a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (mu_head): Linear(in_features=256, out_features=19, bias=True)\n",
       "  (var_head): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=19, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator(state_dim=64, action_dim=19)\n",
    "discriminator.load_state_dict(torch.load(\"discriminator.pth\"))\n",
    "discriminator.eval()   # หรือ .train() ตามกรณี"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "52b37d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.0857,  0.0869,  0.0627, -0.0790, -0.0326,  0.0158,  0.0961,  0.0087,\n",
      "         0.0049, -0.0790,  0.0517, -0.0123, -0.0076,  0.0139,  0.0646, -0.1493,\n",
      "         0.0455,  0.1211, -0.0767], grad_fn=<ViewBackward0>), tensor([0.1988, 0.0971, 0.1328, 0.0000, 0.0217, 0.0204, 0.0371, 0.0000, 0.0000,\n",
      "        0.0193, 0.0215, 0.0000, 0.0523, 0.0000, 0.0000, 0.0207, 0.0766, 0.0990,\n",
      "        0.0967], grad_fn=<ReluBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(discriminator(torch.tensor(data_fullstate[0][\"state\"].reshape(-1, 64))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8a9883b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.7569959e-05, -2.5523271e-04,  5.2417530e-04,  5.4440787e-04,\n",
       "        1.3592407e-04,  2.6334359e-04, -1.3004772e-04, -6.8443049e-05,\n",
       "       -1.4505014e-04,  1.3148678e-04, -6.6024315e-04, -5.8590475e-04,\n",
       "        1.9936003e-04, -3.0740726e-04, -3.6030388e-04, -4.2632362e-04,\n",
       "        1.9244241e-04,  4.3898248e-04,  7.6421195e-05], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fullstate[0][\"action_lowpass\"].reshape(-1, 19)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
