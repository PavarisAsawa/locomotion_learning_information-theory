{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10d091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init\n",
    "import gpytorch\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity, LocalOutlierFactor\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c3884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 5\n",
    "seed = 0\n",
    "# Load fullstate\n",
    "data_fullstate = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_pos = np.empty(num_seeds, dtype=object)\n",
    "data_no_joint_vel = np.empty(num_seeds, dtype=object)\n",
    "data_no_action = np.empty(num_seeds, dtype=object)\n",
    "data_no_imu = np.empty(num_seeds, dtype=object)\n",
    "data_no_fc = np.empty(num_seeds, dtype=object)\n",
    "for i in range(num_seeds):\n",
    "    data_fullstate[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-fullstate-rand-{i}.npz\")    \n",
    "    data_no_joint_pos[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-no_joint_pos-rand-{i}.npz\")\n",
    "    data_no_joint_vel[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-no_joint_vel-rand-{i}.npz\")\n",
    "    data_no_action[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-no_action-rand-{i}.npz\")\n",
    "    data_no_imu[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-no_imu-rand-{i}.npz\")\n",
    "    data_no_fc[i] = np.load(f\"data/performance/HEBB-FULL-STATE_seed-{seed}-no_fc-rand-{i}.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e861841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : X , Y shape :  torch.Size([4000, 19]) torch.Size([4000, 19])\n",
      "TEST : X , Y shape :  torch.Size([1000, 19]) torch.Size([1000, 19])\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "batch_size = 300\n",
    "training_seed = 4\n",
    "\n",
    "state_index = torch.arange(0, 19) \n",
    "state_dim = len(state_index)\n",
    "all_state_dim = 64\n",
    "state_dim = 64\n",
    "action_dim = 19\n",
    "\n",
    "train_x = torch.empty((0, all_state_dim), dtype=torch.float32 ,device=DEVICE)\n",
    "train_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_x = torch.empty((0, all_state_dim), dtype=torch.float32,device=DEVICE)\n",
    "test_y = torch.empty((0, action_dim), dtype=torch.float32,device=DEVICE)\n",
    "for i in range(training_seed):\n",
    "    train_x = torch.cat((train_x, torch.tensor(data_fullstate[i][\"state\"].reshape(data_fullstate[i][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    train_y = torch.cat((train_y, torch.tensor(data_fullstate[i][\"action_lowpass\"].reshape(data_fullstate[i][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "for j in range(training_seed, num_seeds):\n",
    "    test_x = torch.cat((test_x, torch.tensor(data_fullstate[j][\"state\"].reshape(data_no_joint_pos[j][\"state\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "    test_y = torch.cat((test_y, torch.tensor(data_fullstate[j][\"action_lowpass\"].reshape(data_no_joint_pos[j][\"action_lowpass\"].shape[0], -1), dtype=torch.float32,device=DEVICE)), dim=0)\n",
    "\n",
    "train_dataset = TensorDataset(train_x[:,state_index], train_y)\n",
    "test_dataset = TensorDataset(test_x[:,state_index], test_y)\n",
    "\n",
    "print(\"TRAIN : X , Y shape : \",train_x[:,state_index].shape , train_y.shape)\n",
    "print(\"TEST : X , Y shape : \",test_x[:,state_index].shape , test_y.shape)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f867f7",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4f4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276de40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "lr = 5e-5\n",
    "epochs = 125\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(DEVICE)\n",
    "model = ExactGPModel(train_x, train_y, likelihood).to(DEVICE)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4d22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/0 - Loss: 22.191   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/1 - Loss: 22.198   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/2 - Loss: 22.188   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/3 - Loss: 22.183   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/4 - Loss: 22.168   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/5 - Loss: 22.175   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/6 - Loss: 22.178   lengthscale: 0.693   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/7 - Loss: 22.173   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/8 - Loss: 22.190   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/9 - Loss: 22.176   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/10 - Loss: 22.161   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/11 - Loss: 22.170   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/12 - Loss: 22.182   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/13 - Loss: 22.169   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/14 - Loss: 22.183   lengthscale: 0.694   noise: 0.693\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/15 - Loss: 22.159   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/16 - Loss: 22.216   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/17 - Loss: 22.162   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/18 - Loss: 22.172   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/19 - Loss: 22.186   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/20 - Loss: 22.158   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/21 - Loss: 22.153   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/22 - Loss: 22.150   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/23 - Loss: 22.173   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/24 - Loss: 22.143   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/25 - Loss: 22.170   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/26 - Loss: 22.140   lengthscale: 0.694   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/27 - Loss: 22.160   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/28 - Loss: 22.178   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/29 - Loss: 22.140   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/30 - Loss: 22.179   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/31 - Loss: 22.166   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/32 - Loss: 22.148   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/33 - Loss: 22.153   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/34 - Loss: 22.187   lengthscale: 0.695   noise: 0.692\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/35 - Loss: 22.165   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/36 - Loss: 22.163   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/37 - Loss: 22.158   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/38 - Loss: 22.145   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/39 - Loss: 22.164   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/40 - Loss: 22.151   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/41 - Loss: 22.134   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/42 - Loss: 22.151   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/43 - Loss: 22.130   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/44 - Loss: 22.148   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/45 - Loss: 22.148   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/46 - Loss: 22.153   lengthscale: 0.695   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/47 - Loss: 22.152   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/48 - Loss: 22.125   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/49 - Loss: 22.174   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/50 - Loss: 22.141   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/51 - Loss: 22.148   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/52 - Loss: 22.132   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/53 - Loss: 22.138   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/54 - Loss: 22.125   lengthscale: 0.696   noise: 0.691\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/55 - Loss: 22.157   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/56 - Loss: 22.147   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/57 - Loss: 22.126   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/58 - Loss: 22.139   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/59 - Loss: 22.122   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/60 - Loss: 22.148   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/61 - Loss: 22.158   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/62 - Loss: 22.139   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/63 - Loss: 22.140   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/64 - Loss: 22.138   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/65 - Loss: 22.135   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/66 - Loss: 22.138   lengthscale: 0.696   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/67 - Loss: 22.140   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/68 - Loss: 22.159   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/69 - Loss: 22.142   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/70 - Loss: 22.146   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/71 - Loss: 22.130   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/72 - Loss: 22.141   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/73 - Loss: 22.110   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/74 - Loss: 22.136   lengthscale: 0.697   noise: 0.690\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/75 - Loss: 22.137   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/76 - Loss: 22.125   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/77 - Loss: 22.134   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/78 - Loss: 22.134   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/79 - Loss: 22.126   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/80 - Loss: 22.141   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/81 - Loss: 22.132   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/82 - Loss: 22.125   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/83 - Loss: 22.145   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/84 - Loss: 22.120   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/85 - Loss: 22.117   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/86 - Loss: 22.123   lengthscale: 0.697   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/87 - Loss: 22.109   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/88 - Loss: 22.105   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/89 - Loss: 22.116   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/90 - Loss: 22.119   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/91 - Loss: 22.126   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/92 - Loss: 22.097   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/93 - Loss: 22.116   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/94 - Loss: 22.089   lengthscale: 0.698   noise: 0.689\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/95 - Loss: 22.125   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/96 - Loss: 22.096   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/97 - Loss: 22.062   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/98 - Loss: 22.139   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/99 - Loss: 22.104   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/100 - Loss: 22.104   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/101 - Loss: 22.087   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/102 - Loss: 22.126   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/103 - Loss: 22.092   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/104 - Loss: 22.092   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/105 - Loss: 22.093   lengthscale: 0.698   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/106 - Loss: 22.126   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/107 - Loss: 22.107   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/108 - Loss: 22.116   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/109 - Loss: 22.083   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/110 - Loss: 22.121   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/111 - Loss: 22.083   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/112 - Loss: 22.110   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/113 - Loss: 22.094   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/114 - Loss: 22.117   lengthscale: 0.699   noise: 0.688\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/115 - Loss: 22.102   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/116 - Loss: 22.094   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/117 - Loss: 22.099   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/118 - Loss: 22.113   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/119 - Loss: 22.110   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/120 - Loss: 22.092   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/121 - Loss: 22.084   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/122 - Loss: 22.111   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/123 - Loss: 22.097   lengthscale: 0.699   noise: 0.687\n",
      "MultivariateNormal(loc: torch.Size([4000]))\n",
      "Iter 4/124 - Loss: 22.109   lengthscale: 0.699   noise: 0.687\n"
     ]
    }
   ],
   "source": [
    "# ----- Training Loop -----\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    print(output)\n",
    "    loss = -mll(output, train_y.transpose(0, 1).to(DEVICE)).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, epoch, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e91588",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([4000, 19]), while the reported shape of the mean is torch.Size([4000]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:48\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4000, 4000]' is invalid for input of size 76000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval(); likelihood\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[0;32m---> 11\u001b[0m     pred \u001b[38;5;241m=\u001b[39m likelihood(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Pull mean/var (handle single-output vs batched multi-output)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m mean \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mmean          \u001b[38;5;66;03m# single: [T]; multi-batched: [D, T]\u001b[39;00m\n",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:306\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mtrain_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# Create the prediction strategy for\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Concatenate the input to the training input\u001b[39;00m\n\u001b[1;32m    314\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:38\u001b[0m, in \u001b[0;36mprediction_strategy\u001b[0;34m(train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m DefaultPredictionStrategy\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/kernels/scale_kernel.py:124\u001b[0m, in \u001b[0;36mScaleKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprediction_strategy\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_inputs, train_prior_dist, train_labels, likelihood):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:445\u001b[0m, in \u001b[0;36mKernel.prediction_strategy\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprediction_strategy\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    440\u001b[0m     train_inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     likelihood: GaussianLikelihood,\n\u001b[1;32m    444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m exact_prediction_strategies\u001b[38;5;241m.\u001b[39mPredictionStrategy:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexact_prediction_strategies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictionStrategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prior_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pavaris_ws/locomotion_learning_information-theory/.venv/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:52\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.__init__\u001b[0;34m(self, train_inputs, train_prior_dist, train_labels, likelihood, root, inv_root)\u001b[0m\n\u001b[1;32m     48\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m train_labels\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;241m*\u001b[39mtrain_labels\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_shape)], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_shape\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlattening the training labels failed. The most common cause of this error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat the shapes of the prior mean and the training labels are mismatched. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the train targets is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile the reported shape of the mean is \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_prior_dist\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_inputs \u001b[38;5;241m=\u001b[39m train_inputs\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_prior_dist \u001b[38;5;241m=\u001b[39m train_prior_dist\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Flattening the training labels failed. The most common cause of this error is that the shapes of the prior mean and the training labels are mismatched. The shape of the train targets is torch.Size([4000, 19]), while the reported shape of the mean is torch.Size([4000])."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "# ----- Predict on test -----\n",
    "model.eval(); likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    pred = likelihood(model(test_x.to(DEVICE)))\n",
    "\n",
    "# Pull mean/var (handle single-output vs batched multi-output)\n",
    "mean = pred.mean          # single: [T]; multi-batched: [D, T]\n",
    "var  = pred.variance      # single: [T]; multi-batched: [D, T]\n",
    "\n",
    "# Normalize shapes to [T, D]\n",
    "if mean.dim() == 1:\n",
    "    # single output\n",
    "    mean_np = mean.detach().cpu().unsqueeze(1).numpy()   # [T,1]\n",
    "    var_np  = var.detach().cpu().unsqueeze(1).numpy()    # [T,1]\n",
    "    out_dim = 1\n",
    "else:\n",
    "    # batched independent multi-output: [D, T] -> [T, D]\n",
    "    mean_np = mean.detach().cpu().transpose(0,1).numpy() # [T,D]\n",
    "    var_np  = var.detach().cpu().transpose(0,1).numpy()  # [T,D]\n",
    "    out_dim = mean_np.shape[1]\n",
    "\n",
    "std_np   = np.sqrt(np.clip(var_np, 1e-12, None))\n",
    "lower_np = mean_np - 1.96 * std_np\n",
    "upper_np = mean_np + 1.96 * std_np\n",
    "\n",
    "# x-axis (since inputs are high-D, we plot vs sample index)\n",
    "T = mean_np.shape[0]\n",
    "x = np.arange(T)\n",
    "\n",
    "# ----- Optional: ground truth on test set -----\n",
    "# If you have Y_test:\n",
    "# - single-output: Y_test shape [T] or [T,1]\n",
    "# - multi-output:  Y_test shape [T, D]\n",
    "HAS_Y_TEST = 'Y_test' in globals()\n",
    "if HAS_Y_TEST and test_y is not None:\n",
    "    ytest = test_y.detach().cpu().numpy()\n",
    "    if ytest.ndim == 1:\n",
    "        ytest = ytest[:, None]  # [T,1] to match plotting\n",
    "else:\n",
    "    ytest = None\n",
    "\n",
    "# ----- Subplots: 2 columns -----\n",
    "cols = 2\n",
    "rows = math.ceil(out_dim / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols*6, rows*3), sharex=True)\n",
    "if out_dim == 1:\n",
    "    axes = np.array([axes])  # make iterable\n",
    "axes = axes.flatten()\n",
    "\n",
    "for d in range(out_dim):\n",
    "    ax = axes[d]\n",
    "    mu = mean_np[:, d]\n",
    "    lo = lower_np[:, d]\n",
    "    up = upper_np[:, d]\n",
    "\n",
    "    # 95% band + mean\n",
    "    ax.fill_between(x, lo, up, alpha=0.25, label=\"95% CI\")\n",
    "    ax.plot(x, mu, label=\"Predictive mean\")\n",
    "\n",
    "    # overlay test targets if available\n",
    "    if ytest is not None and d < ytest.shape[1]:\n",
    "        ax.plot(x, ytest[:, d], \".\", markersize=2, label=\"Test target\")\n",
    "\n",
    "    ax.set_title(f\"Output dim {d}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# remove empty axes if any\n",
    "for k in range(out_dim, len(axes)):\n",
    "    fig.delaxes(axes[k])\n",
    "\n",
    "fig.tight_layout()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper center\", ncol=3, bbox_to_anchor=(0.5, 1.02))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124300c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
